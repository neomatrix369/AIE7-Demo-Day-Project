# Corpus Quality Assessment PoC

A 4-screen wizard application for assessing corpus quality using AI-generated and RAGAS-generated questions.

## Project Structure

```
├── backend/          # FastAPI backend
├── frontend/         # Next.js frontend
└── README.md         # This file
```

## Usage

1.  **Data Loading Dashboard:** Upon starting the application, you will be greeted with a dashboard that provides an overview of the pre-loaded corpus. This screen gives you a high-level summary of the data you'll be working with.

2.  **Question Groups Overview:** Navigate to the next screen to see the questions generated by both the Large Language Model (LLM) and the RAGAS framework. This allows you to compare the two sets of questions.

3.  **Experiment Configuration:** In this step, you can configure and run experiments. You can select the question groups, configure the experiment parameters, and initiate the experiment.

4.  **Analysis Results Dashboard:** Once the experiment is complete, the results are displayed on this dashboard. The analysis is presented in a 3-level format, providing a comprehensive view of the corpus quality.


## Setup

### Backend
```bash
cd backend
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt
uvicorn main:app --reload
```

### Frontend
```bash
cd frontend
npm install
npm run dev
```

## API Endpoints

- `GET /api/corpus/status` - Corpus overview
- `GET /api/questions/llm` - LLM generated questions
- `GET /api/questions/ragas` - RAGAS generated questions
- `POST /api/experiment/run` - Run experiment
- `GET /api/results/analysis` - Analysis results

## Technologies Used

- **Backend:** FastAPI, Python
- **Frontend:** Next.js, React, TypeScript

## Contributing

Contributions are welcome! Please feel free to submit a pull request.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
